---
title: "Artificial Intelligence"
date: 2024-05-05
---

Artificial Intelligence has presented its extraordinary capabilities in assisting me in my everyday life. Far from mere suggestive algorithm that shows me what I want to see on Youtube, AI is now present in videos, especially short-form, books, and voiceovers. I want to share some thoughts into how it might be tailored for nefarious intents.

For a long time, visual evidence has been concrete evidence of what happened and what not. This “Seeing is believing” idea may no longer hold water in an AI-integrated reality. The ever-evolving deepfake technology has advanced to a point where it is virtually impossible to rely solely on video evidence. The distinction between the real and the fabricated is scarily blurry, which erodes the credibility of graphical content. No longer are the clumsy, easy-to-spot deepfake videos of yesteryears, for they are now startingly realistic, and believable. The worst thing is that AI is never going to be less smart, as it is fed on huge portions of data to reinforce itself.

The main issue resulting from AI-generated content is how fraudulent it can become. Perhaps one of the most unsettling aspects of Deepfake technology is how effortlessly it can be used to fake the voices of famous individuals. With a few clicks, AI algorithms can replicate a celebrity's voice with chilling accuracy. This opens up a Pandora's box of possibilities for content creation, where authenticity is traded for profit. Unscrupulous individuals can, and do, create and disseminate content under the guise of these public figures, capitalizing on their reputation and influence. Looking up “AI Covers” and comparing a video from 2021 with one from 2023 and I already see how fast and advanced AI has progressed. And while this AI-generated music seems rather silly and amasses huge amount of views, its general capabilities mean it can be tapped into for other purposes.

The video aboves shows a compelling example of how AI impersonates a well-known individual to organize a fallacious giveaway event. The features that render the advertisement believable not only come from the video itself but it perfectly takes advantage of the fact that the personality featured was a really philanthropic person. Therefore, a giveway may not come across to his fans as unusual. Had it not been for an unexpected stutter in the advertisement (which, fortunately shows AI still needs to learn) that immediately raised skepticism, the video would have easily caused massive repercussions.

Another prominent fraud stemming from the misuse of AI involves fake invoices and video calls. Imagine receiving a video call from a loved one, pleading for help or money – only it is not them, but a deepfake designed to deceive and manipulate. Examples can be seen everywhere, probably because how relatively easy it is to create fake videos – with only a few prompts. The potential for harm is immense, as it exploits the relationships and familial bonds between individuals.

I believe the proliferation of deepfake videos and AI-generated voiceovers (and graphical content) is going to reach its turning point inevitably, when they will completely overshadow the emails spam that we are bombarded with today. Time will come when perspicacity is deemed essential to distinguish between what is AI-generated and what is not. The need for enhanced digital literacy, and advanced technological solutions will be more pronounced.

It is truly scary.
